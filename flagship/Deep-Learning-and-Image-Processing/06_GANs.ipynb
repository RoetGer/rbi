{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06-GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P0dH-wfiDv2L"
      },
      "source": [
        "# Generative Adversarial Networks\n",
        "\n",
        "In this notebook we will experiment with Generative Adversarial Networks for superresolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UevhtR-ezQnX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cda6491-7cbd-43f6-8315-0f044e193bd0"
      },
      "source": [
        "!pip install scipy\n",
        "!wget --output-document sres.zip https://github.com/mlcollege/rbi/blob/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip?raw=true\n",
        "!unzip -o sres.zip\n",
        "!rm sres/test/target/*gen.png"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "--2020-09-15 20:30:56--  https://github.com/mlcollege/rbi/blob/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/mlcollege/rbi/raw/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip [following]\n",
            "--2020-09-15 20:30:56--  https://github.com/mlcollege/rbi/raw/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/mlcollege/rbi/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip [following]\n",
            "--2020-09-15 20:30:56--  https://media.githubusercontent.com/media/mlcollege/rbi/master/flagship/Deep-Learning-and-Image-Processing/data/sres.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7871005 (7.5M) [application/zip]\n",
            "Saving to: ‘sres.zip’\n",
            "\n",
            "sres.zip            100%[===================>]   7.51M  36.2MB/s    in 0.2s    \n",
            "\n",
            "2020-09-15 20:30:57 (36.2 MB/s) - ‘sres.zip’ saved [7871005/7871005]\n",
            "\n",
            "Archive:  sres.zip\n",
            "  inflating: sres/resize.sh          \n",
            "  inflating: sres/.DS_Store          \n",
            "  inflating: __MACOSX/sres/._.DS_Store  \n",
            "  inflating: sres/test/.DS_Store     \n",
            "  inflating: __MACOSX/sres/test/._.DS_Store  \n",
            "  inflating: sres/test/target/4.png  \n",
            "  inflating: sres/test/target/5.png  \n",
            "  inflating: sres/test/target/2.png  \n",
            "  inflating: sres/test/target/3.png  \n",
            "  inflating: sres/test/target/1.png  \n",
            "  inflating: sres/test/target/0.png  \n",
            "  inflating: __MACOSX/sres/test/target/._0.png  \n",
            "  inflating: sres/test/source/4.png  \n",
            "  inflating: sres/test/source/5.png  \n",
            "  inflating: sres/test/source/2.png  \n",
            "  inflating: sres/test/source/3.png  \n",
            "  inflating: sres/test/source/1.png  \n",
            "  inflating: sres/test/source/0.png  \n",
            "  inflating: sres/train/.DS_Store    \n",
            "  inflating: __MACOSX/sres/train/._.DS_Store  \n",
            "  inflating: sres/train/target/8.png  \n",
            "  inflating: sres/train/target/9.png  \n",
            "  inflating: sres/train/target/14.png  \n",
            "  inflating: sres/train/target/28.png  \n",
            "  inflating: sres/train/target/29.png  \n",
            "  inflating: sres/train/target/15.png  \n",
            "  inflating: sres/train/target/17.png  \n",
            "  inflating: sres/train/target/16.png  \n",
            "  inflating: sres/train/target/12.png  \n",
            "  inflating: sres/train/target/13.png  \n",
            "  inflating: sres/train/target/11.png  \n",
            "  inflating: sres/train/target/10.png  \n",
            "  inflating: sres/train/target/21.png  \n",
            "  inflating: sres/train/target/20.png  \n",
            "  inflating: sres/train/target/22.png  \n",
            "  inflating: sres/train/target/23.png  \n",
            "  inflating: sres/train/target/27.png  \n",
            "  inflating: sres/train/target/26.png  \n",
            "  inflating: sres/train/target/18.png  \n",
            "  inflating: sres/train/target/24.png  \n",
            "  inflating: sres/train/target/25.png  \n",
            "  inflating: sres/train/target/19.png  \n",
            "  inflating: sres/train/target/4.png  \n",
            "  inflating: sres/train/target/5.png  \n",
            "  inflating: sres/train/target/7.png  \n",
            "  inflating: sres/train/target/6.png  \n",
            "  inflating: sres/train/target/2.png  \n",
            "  inflating: sres/train/target/3.png  \n",
            "  inflating: sres/train/target/1.png  \n",
            "  inflating: sres/train/target/0.png  \n",
            "  inflating: sres/train/source/8.png  \n",
            "  inflating: sres/train/source/9.png  \n",
            "  inflating: sres/train/source/14.png  \n",
            "  inflating: sres/train/source/28.png  \n",
            "  inflating: sres/train/source/29.png  \n",
            "  inflating: sres/train/source/15.png  \n",
            "  inflating: sres/train/source/17.png  \n",
            "  inflating: sres/train/source/16.png  \n",
            "  inflating: sres/train/source/12.png  \n",
            "  inflating: sres/train/source/13.png  \n",
            "  inflating: sres/train/source/11.png  \n",
            "  inflating: sres/train/source/10.png  \n",
            "  inflating: sres/train/source/21.png  \n",
            "  inflating: sres/train/source/20.png  \n",
            "  inflating: sres/train/source/22.png  \n",
            "  inflating: sres/train/source/23.png  \n",
            "  inflating: sres/train/source/27.png  \n",
            "  inflating: sres/train/source/26.png  \n",
            "  inflating: sres/train/source/18.png  \n",
            "  inflating: sres/train/source/24.png  \n",
            "  inflating: sres/train/source/25.png  \n",
            "  inflating: sres/train/source/19.png  \n",
            "  inflating: sres/train/source/4.png  \n",
            "  inflating: sres/train/source/5.png  \n",
            "  inflating: sres/train/source/7.png  \n",
            "  inflating: sres/train/source/6.png  \n",
            "  inflating: sres/train/source/2.png  \n",
            "  inflating: sres/train/source/3.png  \n",
            "  inflating: sres/train/source/1.png  \n",
            "  inflating: sres/train/source/0.png  \n",
            "rm: cannot remove 'sres/test/target/*gen.png': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x6LvNkh1nmZa"
      },
      "source": [
        "Define data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zGhBaCCzDhlc",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, mode = 'L'):\n",
        "        self.mode =  mode\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        \n",
        "    \n",
        "    def imread(self, path):\n",
        "        return imageio.imread(path, pilmode=self.mode).astype(np.float)\n",
        "\n",
        "    def load_data(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"test\"\n",
        "\n",
        "        path = glob('./sres/{}/source/*'.format(data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size) if not is_testing else path\n",
        "\n",
        "        imgs_src = []\n",
        "        imgs_trg = []\n",
        "        for img_path in batch_images:\n",
        "            img_src = self.imread(img_path)\n",
        "            img_trg = self.imread(img_path.replace('source', 'target'))\n",
        "\n",
        "            img_src = np.expand_dims(img_src, axis=2) \n",
        "            img_trg = np.expand_dims(img_trg, axis=2) \n",
        "            \n",
        "            imgs_trg.append(img_trg)\n",
        "            imgs_src.append(img_src)\n",
        "\n",
        "        imgs_trg = np.array(imgs_trg) / 127.5 - 1.\n",
        "        imgs_src = np.array(imgs_src) / 127.5 - 1.\n",
        "        self.input_shape = imgs_src.shape[1:]\n",
        "        self.output_shape = imgs_trg.shape[1:]\n",
        "\n",
        "        return imgs_src, imgs_trg\n",
        "\n",
        "    def single_img(self, file_name):\n",
        "        img_src = self.imread(file_name)\n",
        "        #print (img_src.shape)\n",
        "        #img_src = np.expand_dims(img_src, axis=3)\n",
        "        return np.array([img_src]) / 127.5 - 1."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZErpIGRoY0y"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAmQMAdQahF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import scipy\n",
        "import datetime\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, PReLU, LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "#from tensorflow.keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "\n",
        "class SRGAN:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.channels = 1\n",
        "        self.width = output_size[0]\n",
        "        self.height = output_size[1]\n",
        "        self.shape = (self.height, self.width, self.channels)\n",
        "        self.input_shape = (input_size[1], input_size[0], self.channels)\n",
        "\n",
        "        # Number of residual blocks in the generator\n",
        "        self.n_residual_blocks = 16\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        zoom = output_size[0] // input_size[0]\n",
        "        self.upsampling_levels = int(np.log(zoom)/np.log(2))\n",
        "\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch_width = -(-self.width // 2**4)\n",
        "        patch_height = -(-self.height // 2**4)\n",
        "        self.disc_patch = (patch_height, patch_width, 1)\n",
        "\n",
        "        self.optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # We use a pre-trained VGG19 model to extract image features from the target\n",
        "        # image and the generated images and minimize the mse between them\n",
        "        self.vgg = self.get_vgg()\n",
        "\n",
        "        self.discriminator = self.get_discriminator()\n",
        "\n",
        "        self.generator = self.get_generator()\n",
        "\n",
        "        self.gan = self.get_gan(self.discriminator, self.generator)\n",
        "\n",
        "    def get_vgg(self):\n",
        "        \"\"\"\n",
        "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "        third block of the model\n",
        "        \"\"\"\n",
        "        # Set outputs to outputs of last conv. layer in block 3\n",
        "        vgg19 = VGG19(include_top=False, weights=\"imagenet\")\n",
        "        #vgg19 = VGG19(input_shape=(440,512))\n",
        "\n",
        "        #vgg19.outputs = [vgg19.layers[10].output]\n",
        "\n",
        "        # Extract image features\n",
        "        vgg_input = Input(shape=self.shape)\n",
        "        a = Dense(3)(vgg_input)\n",
        "        #vgg_output = vgg19(vgg_input)\n",
        "        vgg_output = vgg19(a)\n",
        "        \n",
        "        #build the model\n",
        "        vgg = Model(inputs=vgg_input, outputs=vgg_output)\n",
        "        vgg.trainable = False\n",
        "        vgg.compile(loss='mse', optimizer=self.optimizer)\n",
        "        \n",
        "        return vgg\n",
        "\n",
        "    def get_discriminator(self):\n",
        "        \"\"\"\n",
        "        Builds the discriminator\n",
        "        \"\"\"\n",
        "\n",
        "        def d_block(layer_input, filters, strides=1, bn=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            if bn:\n",
        "                d = BatchNormalization(momentum=0.8)(d)\n",
        "            return d\n",
        "\n",
        "        disc_input = Input(shape=self.shape)\n",
        "        \n",
        "        d1 = d_block(disc_input, self.df, bn=False)\n",
        "        d2 = d_block(d1, self.df, strides=2)\n",
        "        d3 = d_block(d2, self.df*2)\n",
        "        d4 = d_block(d3, self.df*2, strides=2)\n",
        "        d5 = d_block(d4, self.df*4)\n",
        "        d6 = d_block(d5, self.df*4, strides=2)\n",
        "        d7 = d_block(d6, self.df*8)\n",
        "        d8 = d_block(d7, self.df*8, strides=2)\n",
        "        d9 = Dense(self.df*16)(d8)\n",
        "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "        \n",
        "        disc_output = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "        discriminator = Model(inputs=disc_input, outputs=disc_output)\n",
        "        discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=self.optimizer)\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "        \n",
        "    def get_generator(self):\n",
        "        \"\"\"\n",
        "        Builds the generator\n",
        "        \"\"\"\n",
        "        def residual_block(layer_input, filters):\n",
        "            \"\"\"Residual block described in the SRGAN paper\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "            d = Activation('relu')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Add()([d, layer_input])\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input):\n",
        "            \"\"\"Layers used during upsampling\"\"\"\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
        "            u = Activation('relu')(u)\n",
        "            return u\n",
        "\n",
        "        gen_input = Input(shape=self.input_shape)\n",
        "\n",
        "        # Pre-residual block\n",
        "        c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(gen_input)\n",
        "        c1 = Activation('relu')(c1)\n",
        "\n",
        "        # Propogate through residual blocks\n",
        "        r = residual_block(c1, self.gf)\n",
        "        for _ in range(self.n_residual_blocks - 1):\n",
        "            r = residual_block(r, self.gf)\n",
        "\n",
        "        # Post-residual block\n",
        "        c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
        "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
        "        c2 = Add()([c2, c1])\n",
        "\n",
        "        # Upsampling\n",
        "        upsampling_hierarchy = [c2]\n",
        "        for ul in range(self.upsampling_levels):\n",
        "            upsampling_hierarchy.append(deconv2d(upsampling_hierarchy[-1]))\n",
        "\n",
        "        gen_output = Conv2D(self.channels, \n",
        "            kernel_size=9, strides=1, padding='same', activation='tanh')(upsampling_hierarchy[-1])\n",
        "\n",
        "        generator = Model(inputs=gen_input, outputs=gen_output)\n",
        "        generator.compile(loss='mse', optimizer=self.optimizer)\n",
        "        return generator\n",
        "\n",
        "    def get_gan(self, discriminator, generator):\n",
        "        \"\"\"\n",
        "        Builds the combined model of generator and discriminator\n",
        "        \"\"\"\n",
        "        \n",
        "        source_img = Input(shape=self.input_shape)\n",
        "        target_img = Input(shape=self.shape)\n",
        "\n",
        "        #generate fake image\n",
        "        fake_target = generator(source_img)\n",
        "        #generate features of the fake image\n",
        "        fake_features = self.vgg(fake_target)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Discriminator determines validity of the generated images\n",
        "        validity = discriminator(fake_target)\n",
        "\n",
        "        #build the model\n",
        "        gan = Model([source_img, target_img], [validity, fake_features])\n",
        "        gan.compile(loss=['binary_crossentropy', 'mse'],\n",
        "                              loss_weights=[1e-4, 1],\n",
        "                              optimizer=self.optimizer)\n",
        "        return gan\n",
        "\n",
        "    def train(self, data_loader, epochs=1000, batch_size=1, sample_interval=5):\n",
        "\n",
        "        print(\"Training\")\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "        for epoch in range(epochs):\n",
        "            # ----------------------\n",
        "            #  Train Discriminator\n",
        "            # ----------------------\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "    \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "            #generate fake target\n",
        "            fake_target = self.generator.predict(source_img)\n",
        "\n",
        "            # Train the discriminators (original images = real / generated = Fake)\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "            d_loss_real = self.discriminator.train_on_batch(target_img, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(fake_target, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ------------------\n",
        "            #  Train Generator\n",
        "            # ------------------\n",
        "\n",
        "            self.discriminator.trainable = False\n",
        "            \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "            # The generator wants the discriminators to label the generated images as real\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "           \n",
        "            # Extract ground truth image features using pre-trained VGG19 model\n",
        "            image_features = self.vgg.predict(target_img)\n",
        "\n",
        "            # Train the generator\n",
        "            g_loss = self.gan.train_on_batch([source_img, target_img], [valid, image_features])\n",
        "\n",
        "            elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"Epoch %d,  time: %s, D-loss: %f, G1-loss: %f, G2-loss: %f\" % (epoch, elapsed_time, d_loss, g_loss[0], g_loss[1]))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(data_loader, epoch)\n",
        "                self.save(epoch)\n",
        "\n",
        "    def save(self, filePrefix):\n",
        "        os.makedirs('models/{}', exist_ok=True)\n",
        "        self.discriminator.save_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.save_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.save_weights('models/{}.gan.h5'.format(filePrefix))\n",
        "    \n",
        "    def load(self, filePrefix):\n",
        "        print (\"Loading models.\")\n",
        "        self.discriminator.load_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.load_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.load_weights('models/{}.gan.h5'.format(filePrefix))\n",
        "\n",
        "    def predict(self, data_loader, file_name):\n",
        "        print (\"Predicting..\")\n",
        "        imgs_src = data_loader.single_img(file_name)\n",
        "        imgs_fk = self.generator.predict(imgs_src).reshape(self.height, self.width)\n",
        "        Image.fromarray(((imgs_fk + 1)*127.5).astype(np.uint8), mode='L').save(file_name+'-gen.png')\n",
        "\n",
        "    def sample_images(self, data_loader, epoch):\n",
        "        os.makedirs('results/', exist_ok=True)\n",
        "\n",
        "        imgs_src, imgs_trg = data_loader.load_data(batch_size=1, is_testing=True)\n",
        "        imgs_fk = self.generator.predict(imgs_src)\n",
        "        imgs_src = np.reshape(imgs_src, (imgs_src.shape[0], self.input_shape[0], self.input_shape[1]))\n",
        "        imgs_trg = np.reshape(imgs_trg, (imgs_trg.shape[0], self.height, self.width))\n",
        "        imgs_fk = np.reshape(imgs_fk, (imgs_fk.shape[0], self.height, self.width))\n",
        "\n",
        "        for index in range(imgs_src.shape[0]):\n",
        "            Image.fromarray(((imgs_src[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_src-{}.png\".format(epoch, index)))\n",
        "            Image.fromarray(((imgs_trg[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_trg-{}.png\".format(epoch, index)))\n",
        "            Image.fromarray(((imgs_fk[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_fk-{}.png\".format( epoch, index)))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RoJ02eAApRKo"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrnibKw6pOYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "edd3f7b7-c3fa-4aff-f4fd-ae94e489a8bb"
      },
      "source": [
        "input_size = (128, 128)\n",
        "output_size = (512, 512)\n",
        "\n",
        "dl = DataLoader()\n",
        "deconvgan = SRGAN(input_size, output_size)\n",
        "#deconvgan.train(dl, epochs=10, batch_size=1, sample_interval=100)\n",
        "deconvgan.train(dl, epochs=3000, batch_size=1, sample_interval=100)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Epoch 0,  time: 0:00:10.991614, D-loss: 0.855841, G1-loss: 0.052578, G2-loss: 0.678556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bb0926a34b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeconvgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#deconvgan.train(dl, epochs=10, batch_size=1, sample_interval=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdeconvgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-78a94990ba4b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# If at save interval => save generated image samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-78a94990ba4b>\u001b[0m in \u001b[0;36msample_images\u001b[0;34m(self, data_loader, epoch)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mimgs_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_testing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mimgs_fk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mimgs_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5ad25a722322>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, batch_size, is_testing)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mimg_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mimg_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mimg_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5ad25a722322>\u001b[0m in \u001b[0;36mimread\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpilmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_testing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/sres/test/target/0.png-gen.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rGPwENes18IV",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "#!wget --output-document models/gan.zip http://www.mlcollege.com/data/gan.zip\n",
        "#!unzip models/gan.zip\n",
        "#!mv *.h5 models/\n",
        "\n",
        "#dl = DataLoader()\n",
        "#deconvgan.load('3000')\n",
        "from PIL import Image\n",
        "deconvgan.predict(dl, 'sres/test/source/0.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "agx6XP8nbM4b",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('sres/test/source/0.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ef_FEdCbiYr",
        "colab": {}
      },
      "source": [
        "Image('sres/test/source/0.png-gen.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p3QBZ8PFblNu",
        "colab": {}
      },
      "source": [
        "Image('sres/test/target/0.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxQAB8JyV16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
