{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create power tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "P1P2 = pd.read_csv('data/Effekt FV P1 och P2', sep=',')[['ts', 'Effekt FV P1 och P2']]\n",
    "P5 = pd.read_csv('data/Effekt FV P5', sep=',')[['ts', 'Effekt FV P5']]\n",
    "P6 = pd.read_csv('data/Effekt FV P6', sep=',')[['ts', 'Effekt FV P6']]\n",
    "\n",
    "P1P2['ts']= pd.to_datetime(P1P2['ts'])\n",
    "P5['ts']= pd.to_datetime(P5['ts'])\n",
    "P6['ts']= pd.to_datetime(P6['ts'])\n",
    "\n",
    "data = P1P2.merge(P5, on='ts').merge(P6, on='ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create temperature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_Hallstahammar = pd.read_csv('data/T Ute  Hallstahammar', sep=',')[['ts', 'T Ute  Hallstahammar']]\n",
    "temp_KVV = pd.read_csv('data/T Ute KVV', sep=',')[['ts', 'T Ute KVV']]\n",
    "temp_Knuthagen = pd.read_csv('data/T Ute Knuthagen', sep=',')[['ts', 'T Ute Knuthagen']]\n",
    "temp_Ronnby = pd.read_csv('data/T Ute RĒnnby', sep=',')[['ts', 'T Ute Rönnby']]\n",
    "temp_Skultuna = pd.read_csv('data/T Ute Skultuna', sep=',')[['ts', 'T Ute Skultuna']]\n",
    "temp_prediction = pd.read_csv('data/Temp prognos', sep=',')[['ts', 'Temp prognos']]\n",
    "temp_recommendation = pd.read_csv('data/Temp rekommenderad fram FV', sep=',')[['ts', 'Temp rekommenderad fram FV']]\n",
    "temp_in = pd.read_csv('data/Temp medel åter FV', sep=',')[['ts', 'Temp medel åter FV']]\n",
    "temp_out = pd.read_csv('data/Temp vĄgd fram FV', sep=',')[['ts', 'Temp vägd fram FV']]\n",
    "\n",
    "temp_Hallstahammar['ts']= pd.to_datetime(temp_Hallstahammar['ts'])\n",
    "temp_KVV['ts']= pd.to_datetime(temp_KVV['ts'])\n",
    "temp_Knuthagen['ts']= pd.to_datetime(temp_Knuthagen['ts'])\n",
    "temp_Ronnby['ts']= pd.to_datetime(temp_Ronnby['ts'])\n",
    "temp_Skultuna['ts']= pd.to_datetime(temp_Skultuna['ts'])\n",
    "temp_prediction['ts']= pd.to_datetime(temp_prediction['ts'])\n",
    "temp_recommendation['ts']= pd.to_datetime(temp_recommendation['ts'])\n",
    "temp_in['ts']= pd.to_datetime(temp_in['ts'])\n",
    "temp_out['ts']= pd.to_datetime(temp_out['ts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data to one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(temp_Hallstahammar, on='ts')\n",
    "data = data.merge(temp_KVV, on='ts')\n",
    "data = data.merge(temp_Knuthagen, on='ts')\n",
    "data = data.merge(temp_Ronnby, on='ts')\n",
    "data = data.merge(temp_Skultuna, on='ts')\n",
    "data = data.merge(temp_prediction, on='ts')\n",
    "data = data.merge(temp_recommendation, on='ts')\n",
    "data = data.merge(temp_in, on='ts')\n",
    "data = data.merge(temp_out, on='ts')\n",
    "\n",
    "data = data.rename(columns=\n",
    "                   {\"T Ute  Hallstahammar\": \"temp_Hallstahammar\", \n",
    "                    \"T Ute KVV\": \"temp_KVV\",\n",
    "                    \"T Ute Knuthagen\": \"temp_Knuthagen\",\n",
    "                    \"T Ute Rönnby\": \"temp_Ronnby\",\n",
    "                    \"T Ute Skultuna\": \"temp_Skultuna\",\n",
    "                    \"Temp prognos\": \"temp_prediction\",\n",
    "                    \"Temp rekommenderad fram FV\": \"temp_recommendation\",\n",
    "                    \"Temp medel åter FV\": \"temp_in\",\n",
    "                    \"Temp vägd fram FV\": \"temp_out\",\n",
    "                    \"Effekt FV P1 och P2\": \"power_p1_p2\",\n",
    "                    \"Effekt FV P5\": \"power_p5\",\n",
    "                    \"Effekt FV P6\": \"power_p6\"\n",
    "                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid records and split the data frame at gap borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13829\n"
     ]
    }
   ],
   "source": [
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13104\n"
     ]
    }
   ],
   "source": [
    "data = data[data['temp_in'] != 0.0]\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "data['gap'] = (data['ts'] - data['ts'].shift(1)) != timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflist = []\n",
    "attributes = ['power_p1_p2', 'power_p5', 'power_p6', 'temp_Hallstahammar', 'temp_KVV', 'temp_Knuthagen', \n",
    "              'temp_Ronnby', 'temp_Skultuna', 'temp_in', 'temp_out']\n",
    "start = 0\n",
    "for stop in range(1, len(data)):\n",
    "    if data.iloc[stop]['gap']:\n",
    "        dflist.append(data[start:stop][attributes])\n",
    "        start = stop\n",
    "len(dflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 5 #window size\n",
    "s = 1 #step\n",
    "X_all = []\n",
    "y_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dflist:\n",
    "    for i in range(0, len(df)-w-1, s):\n",
    "        X_all.append(df[i:i+w].values)\n",
    "        y_all.append(df.iloc[i+w]['temp_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12976, 5, 10)\n",
      "(12976, 50)\n",
      "(12976,)\n",
      "(12976,)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "X_all_flat = X_all.reshape(X_all.shape[0], -1)\n",
    "y_all_baseline = X_all_flat[:, -2]\n",
    "\n",
    "print (X_all.shape)\n",
    "print (X_all_flat.shape)\n",
    "print (y_all.shape)\n",
    "print (y_all_baseline.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a GBR model for various train/test splits and compute evaluation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, true_values):\n",
    "    return np.sqrt(((predictions - true_values) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 1.\n",
      "Training iteration 2.\n",
      "Training iteration 3.\n",
      "Training iteration 4.\n",
      "Training iteration 5.\n",
      "Training iteration 6.\n",
      "Training iteration 7.\n",
      "Training iteration 8.\n",
      "Training iteration 9.\n",
      "Training iteration 10.\n",
      "Training iteration 11.\n",
      "Training iteration 12.\n",
      "Training iteration 13.\n",
      "Training iteration 14.\n",
      "Training iteration 15.\n",
      "Training iteration 16.\n",
      "Training iteration 17.\n",
      "Training iteration 18.\n",
      "Training iteration 19.\n",
      "Training iteration 20.\n",
      "[3.8412267473681285, 3.5845522230930356, 3.7505293645288242, 3.7416450267097567, 3.933294716165963, 3.6878937407594083, 3.8412008181113015, 3.6344971690934833, 3.9001544173033618, 3.706636560762584, 3.717979201134607, 3.8794077901574178, 3.707628370871983, 4.041147009494571, 3.932528354810767, 3.898676768357415, 3.7373850600751943, 3.7022200927828752, 3.790211670239497, 3.80058121458492]\n",
      "[0.8267962864831379, 0.7846968222476624, 0.8830378669515391, 0.6952048152894295, 0.7292106288805978, 0.8418961107269054, 0.7167960297203496, 0.8152642825412733, 0.725108360224269, 0.5833021162640946, 0.7771207332251344, 0.6494757172677499, 0.8329573438705739, 1.6170406324634043, 0.8476280102208691, 0.770907245972414, 1.2871588910770273, 0.9405013983282434, 0.581204458139302, 1.0357991940943543]\n",
      "[0.8458028117080054, 0.7652774367129695, 0.876040677478749, 0.9123259752803821, 0.7648493279925268, 0.7789674306905445, 0.7465045907450912, 0.774929454912004, 0.747543860197599, 0.5972705799268088, 0.7476586639609873, 0.6034012984947265, 0.7986742414370361, 1.6058249531343662, 0.8737928220405501, 0.7705011223335292, 0.8422189939811803, 0.9498120537578748, 0.5866741741514789, 0.9457430335570114]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "mean_baseline = []\n",
    "last_values_baseline = []\n",
    "ml_model = []\n",
    "iters = 20\n",
    "train_size = int(0.9*len(X_all))\n",
    "\n",
    "for i in range(iters):\n",
    "    all_data = list(zip(X_all_flat, y_all, y_all_baseline))\n",
    "    random.shuffle(all_data)\n",
    "    X_all_flat_rand, y_all_rand, y_all_rand_baseline = zip(*all_data)\n",
    "    X_train = np.array(X_all_flat_rand[:train_size])\n",
    "    y_train = np.array(y_all_rand[:train_size])\n",
    "    X_test = np.array(X_all_flat_rand[train_size:])\n",
    "    y_test = np.array(y_all_rand[train_size:])\n",
    "    y_baseline = np.array(y_all_rand_baseline[train_size:])\n",
    "    \n",
    "    print (\"Training iteration {}.\".format(i+1))\n",
    "    regr = GradientBoostingRegressor(n_estimators=500)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    \n",
    "    m = np.mean(y_train)\n",
    "    y_mean = np.array([m for i in range(len(y_test))])\n",
    "    \n",
    "    mean_baseline.append(rmse(y_mean, y_test))\n",
    "    last_values_baseline.append(rmse(y_baseline, y_test))\n",
    "    ml_model.append(rmse(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline: 3.7914698158202556 +- 0.1120897742040861.\n",
      "Last values baseline: 0.8470553471994166 +- 0.23414835852342136.\n",
      "ML model: 0.8266906751246712 +- 0.20548856310809796.\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean baseline: {} +- {}.\".format(np.mean(mean_baseline), np.std(mean_baseline)))\n",
    "print (\"Last values baseline: {} +- {}.\".format(np.mean(last_values_baseline), np.std(last_values_baseline)))\n",
    "print (\"ML model: {} +- {}.\".format(np.mean(ml_model), np.std(ml_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network Model\n",
    "\n",
    "The quality of this model is poor in comparison to simple GBR. In needs more elaboration :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "orig_shape = X_train.shape\n",
    "X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(orig_shape)\n",
    "orig_shape = X_test.shape\n",
    "X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(12, input_shape=(w, 10), dropout=0.4, return_sequences=True))\n",
    "model.add(LSTM(12, dropout=0.4, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "#optimizer = RMSprop(lr=0.001)\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11678 samples, validate on 1298 samples\n",
      "Epoch 1/100\n",
      "11678/11678 [==============================] - 16s 1ms/sample - loss: 1177.9274 - val_loss: 631.8058\n",
      "Epoch 2/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 332.3444 - val_loss: 151.0508\n",
      "Epoch 3/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 64.0223 - val_loss: 26.4714\n",
      "Epoch 4/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 16.2977 - val_loss: 14.8127\n",
      "Epoch 5/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 14.1913 - val_loss: 14.4803\n",
      "Epoch 6/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 9.1467 - val_loss: 5.3951\n",
      "Epoch 7/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 5.3418 - val_loss: 3.5799\n",
      "Epoch 8/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 4.4004 - val_loss: 2.9089\n",
      "Epoch 9/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 3.9374 - val_loss: 2.5794\n",
      "Epoch 10/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 3.9732 - val_loss: 2.2384\n",
      "Epoch 11/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 3.3299 - val_loss: 1.9364\n",
      "Epoch 12/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 3.0913 - val_loss: 1.8362\n",
      "Epoch 13/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.8147 - val_loss: 2.0933\n",
      "Epoch 14/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.6998 - val_loss: 1.8513\n",
      "Epoch 15/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.6533 - val_loss: 2.0153\n",
      "Epoch 16/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.7068 - val_loss: 2.0834\n",
      "Epoch 17/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.4215 - val_loss: 2.1171\n",
      "Epoch 18/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.3150 - val_loss: 2.1608\n",
      "Epoch 19/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.2461 - val_loss: 1.9234\n",
      "Epoch 20/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.2062 - val_loss: 1.8528\n",
      "Epoch 21/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.1629 - val_loss: 1.7998\n",
      "Epoch 22/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.0680 - val_loss: 2.1149\n",
      "Epoch 23/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.0664 - val_loss: 2.2779\n",
      "Epoch 24/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 2.0149 - val_loss: 2.1231\n",
      "Epoch 25/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.0191 - val_loss: 2.2085\n",
      "Epoch 26/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 2.0254 - val_loss: 2.3082\n",
      "Epoch 27/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.9808 - val_loss: 2.4401\n",
      "Epoch 28/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.8278 - val_loss: 2.4249\n",
      "Epoch 29/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.8149 - val_loss: 2.1988\n",
      "Epoch 30/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.9309 - val_loss: 2.6955\n",
      "Epoch 31/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.8606 - val_loss: 2.3051\n",
      "Epoch 32/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.8537 - val_loss: 2.5253\n",
      "Epoch 33/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.7542 - val_loss: 2.6090\n",
      "Epoch 34/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.7979 - val_loss: 2.7571\n",
      "Epoch 35/100\n",
      "11678/11678 [==============================] - 15s 1ms/sample - loss: 1.7809 - val_loss: 2.3761\n",
      "Epoch 36/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.8514 - val_loss: 2.7477\n",
      "Epoch 37/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.7827 - val_loss: 2.4854\n",
      "Epoch 38/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.6970 - val_loss: 2.3454\n",
      "Epoch 39/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.6628 - val_loss: 2.3489\n",
      "Epoch 40/100\n",
      "11678/11678 [==============================] - 18s 2ms/sample - loss: 1.7477 - val_loss: 2.4704\n",
      "Epoch 41/100\n",
      "11678/11678 [==============================] - 18s 2ms/sample - loss: 1.6231 - val_loss: 2.3162\n",
      "Epoch 42/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.6815 - val_loss: 2.6330\n",
      "Epoch 43/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5291 - val_loss: 2.3630\n",
      "Epoch 44/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5815 - val_loss: 2.5812\n",
      "Epoch 45/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5899 - val_loss: 2.1005\n",
      "Epoch 46/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.7891 - val_loss: 2.3207\n",
      "Epoch 47/100\n",
      "11678/11678 [==============================] - 12s 1ms/sample - loss: 1.6751 - val_loss: 2.1928\n",
      "Epoch 48/100\n",
      "11678/11678 [==============================] - 12s 1ms/sample - loss: 1.5255 - val_loss: 1.9901\n",
      "Epoch 49/100\n",
      "11678/11678 [==============================] - 12s 1ms/sample - loss: 1.5492 - val_loss: 2.4402\n",
      "Epoch 50/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.6234 - val_loss: 2.5930\n",
      "Epoch 51/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.7032 - val_loss: 2.3873\n",
      "Epoch 52/100\n",
      "11678/11678 [==============================] - 16s 1ms/sample - loss: 1.5291 - val_loss: 2.3778\n",
      "Epoch 53/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5076 - val_loss: 2.3837\n",
      "Epoch 54/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.6761 - val_loss: 2.6319\n",
      "Epoch 55/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.6047 - val_loss: 2.5528\n",
      "Epoch 56/100\n",
      "11678/11678 [==============================] - 18s 2ms/sample - loss: 1.5914 - val_loss: 2.4601\n",
      "Epoch 57/100\n",
      "11678/11678 [==============================] - 16s 1ms/sample - loss: 1.5758 - val_loss: 2.6771\n",
      "Epoch 58/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.6090 - val_loss: 2.3022\n",
      "Epoch 59/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5365 - val_loss: 2.6279\n",
      "Epoch 60/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.5843 - val_loss: 2.5590\n",
      "Epoch 61/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.5054 - val_loss: 2.9044\n",
      "Epoch 62/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.5570 - val_loss: 2.5665\n",
      "Epoch 63/100\n",
      "11678/11678 [==============================] - 16s 1ms/sample - loss: 1.5793 - val_loss: 2.5927\n",
      "Epoch 64/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5808 - val_loss: 2.4713\n",
      "Epoch 65/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5071 - val_loss: 2.5060\n",
      "Epoch 66/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5096 - val_loss: 2.5372\n",
      "Epoch 67/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5799 - val_loss: 2.7413\n",
      "Epoch 68/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5796 - val_loss: 2.2387\n",
      "Epoch 69/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4574 - val_loss: 2.3770\n",
      "Epoch 70/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5207 - val_loss: 2.3290\n",
      "Epoch 71/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4392 - val_loss: 2.5820\n",
      "Epoch 72/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4881 - val_loss: 2.4387\n",
      "Epoch 73/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.4521 - val_loss: 2.5426\n",
      "Epoch 74/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.4121 - val_loss: 2.5454\n",
      "Epoch 75/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4245 - val_loss: 2.5524\n",
      "Epoch 76/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4630 - val_loss: 2.3804\n",
      "Epoch 77/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4125 - val_loss: 2.5662\n",
      "Epoch 78/100\n",
      "11678/11678 [==============================] - 16s 1ms/sample - loss: 1.4765 - val_loss: 2.2707\n",
      "Epoch 79/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.3904 - val_loss: 2.7253\n",
      "Epoch 80/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.3642 - val_loss: 2.4316\n",
      "Epoch 81/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3868 - val_loss: 2.5079\n",
      "Epoch 82/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3760 - val_loss: 2.4101\n",
      "Epoch 83/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3890 - val_loss: 2.2422\n",
      "Epoch 84/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4586 - val_loss: 2.3842\n",
      "Epoch 85/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4590 - val_loss: 2.3122\n",
      "Epoch 86/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3835 - val_loss: 2.6029\n",
      "Epoch 87/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5087 - val_loss: 2.7415\n",
      "Epoch 88/100\n",
      "11678/11678 [==============================] - 12s 1ms/sample - loss: 1.5107 - val_loss: 2.4644\n",
      "Epoch 89/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4074 - val_loss: 2.4482\n",
      "Epoch 90/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3943 - val_loss: 2.4765\n",
      "Epoch 91/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4270 - val_loss: 2.4446\n",
      "Epoch 92/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.5355 - val_loss: 2.7316\n",
      "Epoch 93/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.4026 - val_loss: 2.7811\n",
      "Epoch 94/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.3083 - val_loss: 2.6840\n",
      "Epoch 95/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3963 - val_loss: 2.6216\n",
      "Epoch 96/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4063 - val_loss: 2.6730\n",
      "Epoch 97/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.4124 - val_loss: 2.5790\n",
      "Epoch 98/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3876 - val_loss: 2.4936\n",
      "Epoch 99/100\n",
      "11678/11678 [==============================] - 13s 1ms/sample - loss: 1.3295 - val_loss: 2.3595\n",
      "Epoch 100/100\n",
      "11678/11678 [==============================] - 14s 1ms/sample - loss: 1.4293 - val_loss: 2.3931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147d7a518>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=8, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
