{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "17-Explainability-assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFj9vKMnYsvu"
      },
      "source": [
        "# Convolutional Neural Network Explainability on **MNIST**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWzadigYsvx"
      },
      "source": [
        "## MNIST classification task\n",
        "\n",
        "The MNIST data set is a database of handwritten digits that is commonly used for training various image processing systems. The goal if this task is to implement a classifier of handwritten digits using neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCodqoi3Ysvy"
      },
      "source": [
        "![Mnist data set](https://github.com/jirimaterna/image-processing-2days/blob/master/images/mnist-examples.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnbUUb8NYsvy"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "The data is already shuffled and split to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjQRPjiyYsvz"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pickle\n",
        "from tensorflow.python.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train original shape: {}\".format(X_train.shape))\n",
        "print(\"y_train original shape: {}\".format(y_train.shape))\n",
        "print(\"X_test original shape: {}\".format(X_test.shape))\n",
        "print(\"y_test original shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nv520izYsv4"
      },
      "source": [
        "## Transform the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIHRAFdyYsv5"
      },
      "source": [
        "We need to scale the input values to have the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_pCongYsv6"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rr7O6ZCYsv8",
        "outputId": "90c4a7d0-2bda-4a32-86fb-923c694191d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "print(\"X_train matrix shape: {}\".format(X_train.shape))\n",
        "print(\"X_test matrix shape: {}\".format(X_test.shape))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train matrix shape: (60000, 28, 28, 1)\n",
            "X_test matrix shape: (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dzQVa-MYsv-"
      },
      "source": [
        "Transform the targets into one-hot encoding, i.e.\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0xWKgl4Ysv-"
      },
      "source": [
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9D5zj9AYswb"
      },
      "source": [
        "## Architecture definition\n",
        "\n",
        "Create a sequential model and define its structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkgtiwi3Yswc",
        "outputId": "813fb911-247f-42c6-e7f0-fc39b8058688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1, ), name='conv1_layer'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),  name='conv2_layer'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, name='last_layer'))\n",
        "model.add(Activation('softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1_layer (Conv2D)         (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2_layer (Conv2D)         (None, 8, 8, 32)          25632     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 31,594\n",
            "Trainable params: 31,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKgIKDT9Yswf"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKXll35Yswf"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZ8zNtpYswh"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJD1uf0iYswh",
        "outputId": "bf30b7a2-ef12-429c-ee97-74e9ca1c3ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size = 128, epochs = 10, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.9237 - val_loss: 0.0809 - val_accuracy: 0.9747\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0732 - accuracy: 0.9780 - val_loss: 0.0457 - val_accuracy: 0.9863\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.0416 - val_accuracy: 0.9866\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.0346 - val_accuracy: 0.9885\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0330 - val_accuracy: 0.9898\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.0274 - val_accuracy: 0.9909\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0311 - val_accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0313 - val_accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0299 - val_accuracy: 0.9903\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0264 - val_accuracy: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f26eeed4898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfXbZrbSYswj"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMB2C2WYswk"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-A_4YYYswm",
        "outputId": "f51dbbf5-f0db-41df-edfc-b0a45149af56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
        "print ()\n",
        "print(classification_report(y_test_class, y_pred_class, digits=4))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9913\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9888    0.9949    0.9919       980\n",
            "           1     0.9938    0.9956    0.9947      1135\n",
            "           2     0.9913    0.9922    0.9918      1032\n",
            "           3     0.9882    0.9960    0.9921      1010\n",
            "           4     0.9899    0.9969    0.9934       982\n",
            "           5     0.9865    0.9865    0.9865       892\n",
            "           6     0.9958    0.9864    0.9911       958\n",
            "           7     0.9932    0.9883    0.9907      1028\n",
            "           8     0.9918    0.9908    0.9913       974\n",
            "           9     0.9930    0.9841    0.9886      1009\n",
            "\n",
            "    accuracy                         0.9913     10000\n",
            "   macro avg     0.9912    0.9912    0.9912     10000\n",
            "weighted avg     0.9913    0.9913    0.9913     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wdf_ZnviMam"
      },
      "source": [
        "## Activation Maximization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZWpbzN7BpQX"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUEeG5kpl2DA"
      },
      "source": [
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ612YJABwmw"
      },
      "source": [
        "## Visualize activations of the classification layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y43-BS9BumQD"
      },
      "source": [
        "layer = model.get_layer(name=\"last_layer\")\n",
        "feature_extractor = Model(inputs=model.inputs, outputs=layer.output)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksDEIIX9b9HN"
      },
      "source": [
        "#define the loss function\n",
        "def compute_loss(input_image, filter_index, model):\n",
        "    activation = model(input_image)\n",
        "    filter_activation = activation[..., filter_index]\n",
        "    return tf.reduce_mean(filter_activation)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpdBZRqfsNkQ"
      },
      "source": [
        "#define one learning step\n",
        "import tensorflow as tf\n",
        "@tf.function\n",
        "def learning_step(img, filter_index, model, learning_rate):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img)\n",
        "        loss = compute_loss(img, filter_index, model)\n",
        "    # Compute gradients.\n",
        "    grads = tape.gradient(loss, img)\n",
        "    # Normalize gradients.\n",
        "    grads = tf.math.l2_normalize(grads)\n",
        "    img += learning_rate * grads\n",
        "    return loss, img"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bs-Am1UsUDp"
      },
      "source": [
        "# We start from a gray image with some random noise\n",
        "def initialize_image():\n",
        "    img = tf.random.uniform((1, 28, 28, 1)) * 0.25\n",
        "    return img"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mH_elCCTRPs"
      },
      "source": [
        "def deprocess_image(img):\n",
        "    img -= img.mean()\n",
        "    img /= img.std() + 1e-5\n",
        "    img *= 0.15\n",
        "    img = np.clip(img, 0, 1)\n",
        "    img *= 255\n",
        "    img = -np.clip(img, 0, 255).astype(\"uint8\") + 255\n",
        "    return img"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za4AY2k7s7ku"
      },
      "source": [
        "# Run the training algorithm\n",
        "def visualize_filter(filter_index, model):\n",
        "    iterations = 100\n",
        "    learning_rate = 10.0\n",
        "    img = initialize_image()\n",
        "    for iteration in range(iterations):\n",
        "        loss, img = learning_step(img, filter_index, model, learning_rate)\n",
        "    print (\"Training step {}, loss: {}\".format(iteration+1, loss))\n",
        "    # Decode the resulting input image\n",
        "    img = deprocess_image(img[0].numpy())\n",
        "    return loss, img"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLtOx9g4tVV3",
        "outputId": "9badb6c7-2cff-499a-fb67-5a02dfd81265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "#visualize number 4\n",
        "class_number = 4\n",
        "loss, img = visualize_filter(class_number, feature_extractor)\n",
        "keras.preprocessing.image.save_img(\"{}.png\".format(class_number), img)\n",
        "source = io.imread(\"{}.png\".format(class_number), as_gray=True)\n",
        "source = cv2.resize(source, (50, 50))\n",
        "plt.imshow(source, cmap='Greys')\n",
        "plt.show()\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training step 100, loss: 4383.95556640625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcW0lEQVR4nO2dbaxeVZXH/4tSaKVgKa219tZpCQio6YBpGo18MDgkTDFCoplgJhMmIemXmQSjE+3MJJOYzAf84ksyM5pG1E5ixNcEQpxMGMAYFKtAQVpqaak0bbm01LYWVKDQNR/uqT7nf9Z99r7nOc/L7f7/kqZ3n3te1rPPWfc8a+31Yu4OIcS5z3njFkAIMRqk7EIUgpRdiEKQsgtRCFJ2IQpByi5EIQyk7GZ2k5ntMbN9ZralK6GEEN1jbdfZzWwBgGcB3AjgEIBfAviEuz/T55ihLOqbWd/xbNt6ieaBt7WZq9R1c/bJuW60T86153pMm3MOi5x5aTP/Off9zJkzyfOOC3cPP/T5A5xzI4B97r4fAMzsHgC3AJhV2dtw3nnn9R0DwMKFC2vj889vfqwFCxb0vc7p06eT2958882+5wDSf3iih4/lZ6IH64033kjKxp85mheG5eP5juaxzR+ALhQ1umd8DH/mHPl5bqPrvPrqq7VxzrORQ+p5yXkpzcYgX+NXAzjYMz5UbRNCTCCDvNmzMLPNADYP+zpCiP4MouyHAazpGU9V22q4+1YAW4F2NnuO/cRfoaKv+qmvOm2+Vl544YWNfXgbyxZ9JU99xhwfRI55kzJlIlgW/oqbQ1s7n49j+aP553ngr/GRLHwM36Nx5o90ee1Bvsb/EsCVZrbOzC4AcBuA+7oRSwjRNa3f7O7+hpn9I4D/BbAAwNfdfVdnkgkhOmUgm93dfwTgRx3JIoQYIoqgE6IQhu6NHxR2ULQNZkg5vSLnFW/j8cUXX9w45tJLL62N//jHP9bGvD4b7cNOsBznW+TI4X14HJ2XHYos2+uvv944hu9JjvMwtR4ewfO/ZMmSxj58Hh5HsjC8rh45JYfltBumM1BvdiEKQcouRCFI2YUohIm32Zmc2OAoTjlls0e+gAsuuKDvOLLz2b5jG/33v/9945jXXnutr6w5RMekAkzanLdNwlBOkk4bX8wf/vCHxrZUEA3fQyBtx0fHMHzf28aw5+RS9Dtvv2vozS5EIUjZhSgEKbsQhTDvbPaIYRUS4ESLiy66qDaObL1XXnmlNj516lRtHNmZw4LXxNnHkFOUgW3RnESeuf4+l5RsQDrZZ/HixY1tfJ9z7PyUX6JNwhCQrt+QetZlswshpOxClIKUXYhCkLILUQjnhINuWKQcS5wkEm2LEkdGBTujOHGEg3mApryT1OU3J3iKYeda5FTlQBxOhIkCW9hR1qYYaUQq8WtcBSeFEPMIKbsQhSBlF6IQRm6zz7XjSBcdVYB2tmcqoCGyeaNEl2GQM08cLPKWt7ylNs4J/OiiK05XtJElVcwCaNeRh+36nMCuQZNcZpNFNrsQooaUXYhCkLILUQhSdiEKYeQOul6nVxTgwEEQOR1ac/ZhZ1qOcypVTWWcbXs5u2vRokWNfXh++TNHGWD8mXneuupW2oac9k9tqguxg4sDo6JMxTb3vgvn5iDn0JtdiEKQsgtRCFJ2IQphrEE1kW3N29jmiuw0tlcjuywVINMmwCGnu8iw4GtH1VR4Xt761rfWxtE8cVDQyy+/XBtzMMko4c8c+Rw4cIj9OZHPgf0SXSSfDCvQaxD0ZheiEKTsQhSClF2IQhipzW5mSVuGbSoeR+vjOXZkqmtoZP+xvcdEiTBs444T7ii7Zs2a2jjyORw/frw2np6e7l6wlvD9yOmiy36KF154oXHM7373u77XiXwbXEWYn9NobsedVKQ3uxCFIGUXohCk7EIUQlLZzezrZnbUzHb2bFtmZg+Y2d7q/0v7nUMIMX5yHHTfBPAfAP67Z9sWAA+6+11mtqUafzZ1InevBSxEjjV2dOS01clJUGEHHTvkLrvsssYx7JhheaMAHz4mJ0CjDTlVc1gWri4bwUkgqXZKXRE5blMOube97W2NY9hBx+fgoBugGZDEz1j0zI2rYk/k+Oudu36JSsk3u7v/BMBx2nwLgG3Vz9sA3JoWUwgxTtouva1097NrMi8CWDnbjma2GcDmltcRQnTEwOvs7u5mNut3GnffCmArAPTbTwgxXNoq+xEzW+Xu02a2CsDR3AN7bYrITmObI6c7B9tUkd3C7ZbZdluxYsUsEv8ZDpiJgm5SNm5XxR/4PDmtoFO26TiJbFG20dmvMjU11TiGPyM/P/wcRNuOHTtWG0cVg9lm5+dykCqw/c4bzVPvc/jqq6/Oeq62S2/3Abi9+vl2APe2PI8QYkTkLL19G8CjAK4ys0NmdgeAuwDcaGZ7AfxVNRZCTDDJr/Hu/olZfvXhjmURQgyRsXZxbWPDRMfwGnNOBw+2hThhAgCWL19eG7ONGMUJsO186tSpvr9vS8pmBJrr6suWLauNU2u2QFwUY65EsvEa+apVqxr78DaW/5JLLmkcw/b1yZMna2NO9AGAEydO1MZs9+bEADCj9Ifk+oEULitEIUjZhSgEKbsQhSBlF6IQxuqg64qcxIUUXK0EAN7+9rfXxuwwipJPOCCDnT1dOehy2v9ysMjSpUtr46g6DyfYRMk+XcBVc9avX9/Yh+efZYnmnxN52PkWOejYicdEgVI8dzxvbZNncqrStjkvoDe7EMUgZReiEKTsQhTCOWGz58C2EAciRMkObIexnRYF4nCwCNvwXZFjp/G1jxw5UhtHBTt4XnISMVIdTSM79PLLL6+Nr7nmmsY+bCuzbb1v377GMXv37q2NDx8+XBtzVdgcos+X8r20LW7BVY85eCcK5OqVr9919WYXohCk7EIUgpRdiEIYq80e2XKp9ePoGLYjo3VRXvfk87z++uvJ8/I6dXQM24TPP/98Y59hENlqvMbPxTe4OCOQthnbdDqJ7tnq1atr4+uuu66xD8u7c+fO2nj//v2NY3gbJyJ1tdY9rG62qfkfpPil3uxCFIKUXYhCkLILUQhSdiEKYawOusjZw5VReLxo0aLGMbwtctCxo4b3ic7LlV44eSNqGcwOlT179tTGkVNpWHDiCFd2iRx0fAxX4Y3uWapSSuTweuc731kbX3XVVY19OIjm6NF6EeOokioHR7VxyPFnjOTP6ULUhlTL8ug6ctAJIWpI2YUoBCm7EIUwcUE1HFTANmOUfJJTYIFtOQ5OiBJh2F5i/wEHhgBNeR999NGkbMMiFaARJcJwsg+fo6vupVyYgivHAnHQUi9R8YpU4ZKoKiw/P6muRMDwuriyTZ7qajwXWfRmF6IQpOxCFIKUXYhCmDibne1iXuuO7Ey23aICBbwmy/vwOjwA/Pa3v62N2a7ndXeg2UUmWsseFSn7NbKToy6nqXOmbMacbjVR5xkuEPHSSy/VximbPiLqIsPzkLOePyybPbXOPsh19WYXohCk7EIUgpRdiEKQsgtRCGN10EVB/ewM4U4tkYOIt+V0CslJMOBj2EHHASdAM+iHnT9R8gxfZ1jtfvkzR51QWBYe5ziIOMnl2muvbeyzdu3a2jhKXuKkoV27dtXGbSrF5gRyMcNyxrW5VqqKjqrLCiGk7EKUQlLZzWyNmT1sZs+Y2S4zu7PavszMHjCzvdX/41tQFkIkybHZ3wDwaXd/wswuBvC4mT0A4O8BPOjud5nZFgBbAHx2LhePih6wXZwKrMglVfE0soU4aINtxMjO5KAUDgKKgoI4iKMrm50/E88BXxdoBhexzZ4D2+gf+9jHGvuwXR/N/+OPP14bP/TQQ7Vx1Hk3RWTTDstHMip6524gm93dp939iernlwHsBrAawC0AtlW7bQNwa3txhRDDZk42u5mtBXAdgO0AVrr7dPWrFwGs7FQyIUSnZC+9mdkSAD8A8El3P0VfHdzMwu8PZrYZwOZBBRVCDEbWm93MFmJG0b/l7j+sNh8xs1XV71cBaBqAANx9q7tvcPcNXQgshGhH8s1uM6/wuwHsdvcv9PzqPgC3A7ir+v/eYQjYJqAhcpxx9hk70qJjOBOL2wG/613vahzDLZvXrVtXG19//fWNY7Zv314bc2ARnyO6DmeRAcCKFStq45Ur65YWnwNoOspWrVpVG0eZZpxJxm2youCdHTt21MZR1VoOouF2UFEgFFei4arBkYOU54WdlFFGJAfi8LMSBerkBHLx/Kbals2FnK/xHwTwdwCeNrMnq23/ghkl/66Z3QHgAIC/aS2FEGLoJJXd3R8BMNufkw93K44QYlgogk6IQhhrIkwOOcEvvC2qNst2JVeUiY5hm+rAgQO18eHDhxvHcGcTTvhYv3594xi2Cdm2i9oZc2Vbts+Bpr3H/o+oUi/vw/JHlWzYH8JzeejQocYxvI2DpwDgueeeq4258m0kP+/D953t82ifI0eO1MZRpRq+DtvskQ+CE7SigKVUgE/kw8q14/VmF6IQpOxCFIKUXYhCsFEm5s8WZdeP1Lop0LQRozXOlP0a2T1si/Ka82233dY4ZtOmTbXx9PR0bfz88883jmHbn7vKvPe9720cw/JG9h9Xx2W7OOpow/PN8r7wwguNYzihhj/Ps88+2ziG5zLyOfB6/dTUVG38nve8p3EM31e2vyP/AX8mtq2j9XB+DvmYaJ54LiOfDz+nfO2c4hXuHu6kN7sQhSBlF6IQpOxCFIKUXYhCGHlQTcrBwL9nh1HUJihqw8twBRwOlIjk4sAJrgyb0yqaHTnsmAKa8qcCQ4BmlZbf/OY3jX3YccZzEDln2VHGiSNRUgg7nlJVYYGm44lbOANNBxxXwIkcjJwsw+2WIwcdOy75nrHDNNonmhemi1bQav8khEgiZReiEKTsQhTCyG323gSByE7mBALeJyqewPZ3ZAuligBE9je3ZOaElMhmZNjOj2R78cUXa2O2/6IAjT179tTGP/vZzxr7nDhxojZmm/F973tf4xi22dm25iAhoFkFloN5ovvM1WWvvPLKxj5ctINl+elPf9o45oknnqiNH3nkkdo4qqibstmj5B++r/wMRgEzOT6TYaI3uxCFIGUXohCk7EIUwsStszNsp0V2Tk7iAifH8Prx1Vdf3TiGbXRe94062nBRSrZfI1tu586dtTGvofO6O9Bc237qqaca+0TdbHuJ/Adss/NnPHbsWOMY/kx8j6POtbwtei52795dG7PNy3MNAE8//XRtzHMbFYfga6eKSQJNu57PG3WYjZ6XUaI3uxCFIGUXohCk7EIUgpRdiEIYeaWaVFBNcEzfMdB0fET7cCVSTqq4+eabG8dcc801tTFXpGVnENAMMGHHWeRU4iozOdVJUp1DgHTQRtQFJ6qK2k82oDn/nLgTdZ7ZuHFjbRx1avn5z39eG3O12cgByfPCTsic5z3nmUsRXWdUuqZKNUIUjpRdiEKQsgtRCGNNhMn5PSeoRIUE2N6LCiHwNq5UGlU3PXjwYG3MSRVRwQgOBOFzHD9+vHHMsGy5VFJRFOSR6kiSA9vs3FUGaNr+UbAOJ91wgFIbogAflpe7znIwz3xFb3YhCkHKLkQhSNmFKISR2uxmVrMbo84tbGcuWbKkNo7WbDlh5Yorrmjsw4Ue2XaL1o+3b99eG3/jG9+ojaPOo5MEzyWPh7UWzPcsKrLJsQWRzR51uZkr7KdYtmxZYx8ukvHrX/+6Nh7lfR7mWrze7EIUgpRdiEKQsgtRCEllN7NFZvYLM3vKzHaZ2eeq7evMbLuZ7TOz75hZM8NfCDEx5DjoXgNwg7u/YmYLATxiZv8D4FMAvuju95jZVwHcAeAryQv2OOVygjq40mpUXfYd73hHbRwF3nASBVcDjZIquNVwqvJLDlFSRZSQ0kvbCiepKj9tnEGRrBz4xOflIBWgGWzEFXaBdsEs3F2Hn4UoqIsdcByAxa27geY94eeSny+g+WxHAUypRJ6I3meq3/7JN7vPcLbGzsLqnwO4AcD3q+3bANyalEoIMTaybHYzW2BmTwI4CuABAM8BOOnuZ/80HQIQFlE3s81m9piZPdaFwEKIdmQpu7u/6e7XApgCsBFAszrj7MdudfcN7r6hpYxCiA6YU1CNu580s4cBfADAUjM7v3q7TwFolk0lOKgmgu0YtkGiAAe2/yLYZj9y5Eht3KYaaPRZUp8vshnZzuTr5tjs0XXZdo4Ch+ZKZLOzXczX4c40QLPLDd+PtnCgFleBjfwU/Exx4BYHCQFNXxJ3j426uuYUHOH5TSWOMf0SmXK88SvMbGn182IANwLYDeBhAB+vdrsdwL1zkkoIMVJy3uyrAGwzswWY+ePwXXe/38yeAXCPmf07gB0A7h6inEKIAUkqu7v/CsB1wfb9mLHfhRDzAEXQCVEIE9/+iYkcLOyge+mllxr7cIAGBz20cV5FWXvcKign04yDddghFx2TymgD8lpnzZXoM0ftrnuJnJ9dVMSJYCcYOwdz2j8xkYP0wIEDA1+HHbPRPjy30Xlzg670ZheiEKTsQhSClF2IQhi5zd5rN3ZVlYNbHPM4gm2jKFiE7W8eR8fweXOSH1LniFoGM10EzABN259t9CjJ6KKLLup7jshmz7Ff2RbN+YypgKQokSr1HEbX5SCaKNmH4ecluq883zwvg9xnvdmFKAQpuxCFIGUXohBGarOfOXOmtr49zk6XbD+x3Qk0K5FyF5ko2YE7vvD6a1QxlW1ctosj2ThOIPJTtJlLthm5287SpUsbx3BHFbZnI9n4OtxlF2jOLydF5ST/8DjyDXCyDD8bXflD+Dw5XWhz/De5yTJ6swtRCFJ2IQpByi5EIUjZhSiEkQfVdOXsGBR23ETJBOwE45bBUdUc3hYFcTDsIGIHHf8eyKs62ga+Pyx/5FTiuVy8eHHyOtx+K0qw4Wo2OdVmOWiJ5Y8cgdyeiqvLRvPPjr7Dh+uFmnLaWUX3MJW8FD2nvZ+xn1NWb3YhCkHKLkQhSNmFKAQbVRALAJjZ6C6WICcRJkVOUBCPI9t0+fLltTHbvNF1OOCEg3lmOy4FzwuPOYAGaHbk4c8TtUnmbVEBjOnp6dqYi5JESUWpYKM1a9Y0jlm7dm3fcdQmnG3ro0eP1sa7du1qHMM+iCh5hu14/ozRfe71E7k73D2sxqE3uxCFIGUXohCk7EIUwsjX2SeVaP2/i66nbWA7LVpf5jXbrmRLfeZobZjlY59DZI/zfEe+jFQRkqiQBtvsnJQTdYvlNXP2S3BMANDs7Lp6db3VYZSwwr6NSBbujMO+gGieev0qWmcXQkjZhSgFKbsQhSBlF6IQ5KCrGFbVnFSQSnQdTjaJHFXD6qiSInLQsbMwatHMpLrgAOnuKJETjM/LgStRYhJ/Jg74iSoFsXOQHXY8Bpqtn6Nnge8rz2XkoOsNCJODTgghZReiFKTsQhTCOWmzR7YQb8upyJlTOCB1HQ7QiAJBOKiDA0NGmayUIpoDDlxhGz6n8m1OURNOVuJEmejafN6oui8XJdm7d29tzPcDaBar4PseFfngghYcQBNdi234aP577fh+vhy92YUoBCm7EIWQrexmtsDMdpjZ/dV4nZltN7N9ZvYdM0t3HxRCjI252Ox3AtgN4KwR+nkAX3T3e8zsqwDuAPCVjuXrDLb3IrueYXsvZ8081fWU11qB5tpvjm9gXESyRXbwpBLZtJzIc/Dgwdo4KjLBPh8+b9QtiIuRRjEL/LxwLEEkf+9z2O+5znqzm9kUgJsBfK0aG4AbAHy/2mUbgFtzziWEGA+5X+O/BOAzAM6+6i4DcNLdz/6ZOQRgdXSgmW02s8fM7LGBJBVCDERS2c3sIwCOuvvjbS7g7lvdfYO7b2hzvBCiG3Js9g8C+KiZbQKwCDM2+5cBLDWz86u3+xSAw33OIYQYM3OqLmtmHwLwT+7+ETP7HoAf9DjofuXu/5U4fijRITkBM+zoyAmCSHXniBIk2AHHyRuRbBxIwQ6jqFLNpHTWORfhIKeozTOTU9GH71l0D/n5yKl63Pssnz59GmfOnOm8uuxnAXzKzPZhxoa/e4BzCSGGzJzCZd39xwB+XP28H8DG7kUSQgwDRdAJUQjnZCJM5IdIBaq0KV4RFRJgG519A6kunMDoClPkJAyNq8LuOGF7e1gdcyNSfqLI56PqskKIGlJ2IQpByi5EIZwTNnuOXZmyu4Zli+asv3IiybCKV+R0rk35GEqw2SeJnAIqOUldgN7sQhSDlF2IQpCyC1EIUnYhCmHkDrpUVddUUEdO8kBO5Vi+ThQgkzpv1IqYyQnQ4CCaUTkLcwKJ5JDLIycZi7dFzxw/CznJM7n3SG92IQpByi5EIUjZhSiEsdrsOdVZ2caNbBYODomKDaRs9OgY3sY2eo7Ny/JGSS7jsosnuYrtfCMnYImfn8jnw0VUeDxIt2G92YUoBCm7EIUgZReiEKTsQhTCnKrLDnwxM0856JiugmpSDrrIocLbeJwT4JATVMOOsq4qx7YJNkrNt4JsYiYpqMbdO68uK4SYR0jZhSgEKbsQhTBym31E10luy2m/nPIpZNpPfcfDJOVziPwU7D9I2ZA55FZSGQYl+hhkswtROFJ2IQpByi5EIZwT1WXb2IQ5tlwX9vc4bcaUfR0lwnThY8hZc87xmaRki1BcwOzozS5EIUjZhSgEKbsQhSBlF6IQzgkHHdOVw26+V1rNaR00DHKcb+y0iwJ8UuQ4GMWf0ZtdiEKQsgtRCFJ2IQph1Db7MQAHACyvfu6EIdvWnco6AsYub07BhYqxyzpH5oO8fzHbL0aa9fani5o95u4bRn7hFswnWYH5Je98khWYf/Iy+hovRCFI2YUohHEp+9YxXbcN80lWYH7JO59kBeafvDXGYrMLIUaPvsYLUQgjVXYzu8nM9pjZPjPbMspr52BmXzezo2a2s2fbMjN7wMz2Vv9fOk4Zz2Jma8zsYTN7xsx2mdmd1fZJlXeRmf3CzJ6q5P1ctX2dmW2vnonvmNkF45b1LGa2wMx2mNn91XhiZc1hZMpuZgsA/CeAvwbwbgCfMLN3j+r6mXwTwE20bQuAB939SgAPVuNJ4A0An3b3dwN4P4B/qOZzUuV9DcAN7v6XAK4FcJOZvR/A5wF80d2vAHACwB1jlJG5E8DunvEky5pklG/2jQD2uft+d38dwD0Abhnh9ZO4+08AHKfNtwDYVv28DcCtIxVqFtx92t2fqH5+GTMP5WpMrrzu7q9Uw4XVPwdwA4DvV9snRl4zmwJwM4CvVWPDhMqayyiVfTWAgz3jQ9W2SWelu09XP78IYOU4hYkws7UArgOwHRMsb/W1+EkARwE8AOA5ACfd/Wy96kl6Jr4E4DMAzob/XYbJlTULOejmgM8sXUzU8oWZLQHwAwCfdPdTvb+bNHnd/U13vxbAFGa+6V09ZpFCzOwjAI66++PjlqVLRhkbfxjAmp7xVLVt0jliZqvcfdrMVmHmrTQRmNlCzCj6t9z9h9XmiZX3LO5+0sweBvABAEvN7PzqjTkpz8QHAXzUzDYBWATgEgBfxmTKms0o3+y/BHBl5dG8AMBtAO4b4fXbch+A26ufbwdw7xhl+ROVDXk3gN3u/oWeX02qvCvMbGn182IAN2LGz/AwgI9Xu02EvO7+z+4+5e5rMfOcPuTuf4sJlHVOuPvI/gHYBOBZzNhq/zrKa2fK920A0wBOY8YmuwMzttqDAPYC+D8Ay8YtZyXr9Zj5iv4rAE9W/zZNsLzrAeyo5N0J4N+q7ZcD+AWAfQC+B+DCcctKcn8IwP3zQdbUP0XQCVEIctAJUQhSdiEKQcouRCFI2YUoBCm7EIUgZReiEKTsQhSClF2IQvh/KByJ2CwcQpwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Ko9ndrZi-x"
      },
      "source": [
        "## Now visualize some filters of the convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASjiFQAiZpWT"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}